---
title: "Logistic"
author: "Andrew Thornton"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages
```{r}
library(caret)
library(tidyverse)
source('Functions.r')
source('Data_Model.r')
```

## Prepare Data
```{r data prep, echo=TRUE}
# Retrieve data
df <- data.frame(get_data_with_success())

# Subset data into train and test datasets
df_sets <- subset_data(df)
StudentTrain <- data.frame(df_sets[1])
StudentTest <- data.frame(df_sets[2])
```

## Logistic Regression Model
```{r logistic, echo=TRUE}
# Train model
set.seed(456)
logistic_model1 <- glm(Success ~., data = StudentTrain, family = "binomial")
summary(logistic_model1)

# Generate predictions on the test set
logistic_pred_prob <- predict(logistic_model1, StudentTest, type = "response")
logistic_pred_class <- ifelse(logistic_pred_prob > 0.5, "1", "0") 

#Saves Predictions to .RDS file for use in ModelAnalysis
saveRDS(logistic_pred_class, file="logistic_test.rds")

# Factor predictions for consistency
logistic_pred_class <- factor(logistic_pred_class, levels = levels(StudentTest$Success))

# Create confusion matrix
(logistic_conf_matrix <- confusionMatrix(logistic_pred_class, StudentTest$Success))
```

```{r logistic revised, echo=TRUE}
# Train model
logistic_model2 <- glm(Success ~ StudyTimeWeekly + Absences + Tutoring + ParentalSupport
                      + Sports + Music, data=StudentTrain, family="binomial")
summary(logistic_model2)

# Generate predictions on the test set
logistic_pred_prob <- predict(logistic_model2, StudentTest, type = "response")
logistic_pred_class <- ifelse(logistic_pred_prob > 0.5, "1", "0") 

# Factor predictions for consistency
logistic_pred_class <- factor(logistic_pred_class, levels = levels(StudentTest$Success))

# Create confusion matrix
(logistic_conf_matrix <- confusionMatrix(logistic_pred_class, StudentTest$Success))
```
## Optimal Cutoff Value
```{r cutoff, echo=TRUE}
cutoff <- seq(0, 1, length = nrow(StudentTrain))
acc <- numeric(nrow(StudentTrain))
sen <- numeric(nrow(StudentTrain))
spec <- numeric(nrow(StudentTrain))

Actual <- StudentTrain$Success
predicted.probability.train <- predict(logistic_model1, type = "response") 

## Store values in a data frame
acc.table <- data.frame(Cutoff = cutoff, ACCURACY = acc,SENSITIVITY = sen, SPECIFICITY = spec)

for (i in 1:nrow(StudentTrain)) {
  Predicted <- ifelse(predicted.probability.train > cutoff[i], "1", "0") 
  Predicted <- factor(Predicted, levels = levels(StudentTest$Success))
  
  confusion <- table(Actual,Predicted)
  acc.table$ACCURACY[i] <- (confusion[1,1]+confusion[2,2])/sum(confusion)
  acc.table$SENSITIVITY[i] <- sum(predicted.probability.train > cutoff[i] & Actual == "1")/sum(Actual == "1")
  acc.table$SPECIFICITY[i] <- sum(predicted.probability.train <= cutoff[i] & Actual == "0")/sum(Actual == "0")
}

plot(ACCURACY ~ cutoff, data = acc.table, type = "o",xlab="Cutoff",ylab="Accuracy",col="blue",lty=2, ylim=c(0,1))
lines(SENSITIVITY~cutoff,data = acc.table, type="o",col="green",lty=2)
lines(SPECIFICITY~cutoff,data = acc.table, type="o",col="red",lty=2)
z <- which.max(acc.table$ACCURACY)
cutoff[z]
```