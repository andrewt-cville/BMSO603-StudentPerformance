---
title: "DecisionTree"
author: "Andrew Thornton"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Packages

```{r}
library(tree)
library(caret)
library(tidyverse)
source('Functions.r')
source('Data_Model.r')
```

## Get and Subset Data
``` {r}
df = data.frame(get_data())
df_sets = subset_data_v(df, 0.6)
StudentTrain = data.frame(df_sets[1])
StudentTest = data.frame(df_sets[2])
```

``` {r}
# Decision tree model
tree_model <- tree(GradeClass ~ ., data = StudentTrain)

plot(tree_model)
text(tree_model, pretty = 0)

summary(tree_model)

# Pruned Decision tree

# Perform cross-validation to find the optimal size of the tree
cv_tree <- cv.tree(tree_model, FUN = prune.misclass)

# Plot the cross-validation results
plot(cv_tree$size, cv_tree$dev, type = "b", xlab = "Tree Size", ylab = "Deviance")

# Find the optimal tree size that minimizes the deviance
optimal_size <- cv_tree$size[which.min(cv_tree$dev)]

# Prune the tree to the optimal size
pruned_tree <- prune.misclass(tree_model, best = optimal_size)

# Plot the pruned tree
plot(pruned_tree)
text(pruned_tree, pretty = 0)

summary(pruned_tree)
```

## Predictions
NOTE - I think we want to shift this to predict against the pruned tree - right?
``` {r}
# Predictions on the test set
tree_pred_class <- predict(tree_model, StudentTest, type = "class")

# Consistent levels
tree_pred_class <- factor(tree_pred_class, levels = levels(StudentTest$GradeClass))

# Confusion Matrix
tree_conf_matrix <- confusionMatrix(tree_pred_class, StudentTest$GradeClass)
print(tree_conf_matrix)

# Binary Sensitivity and Specificity Calculation
tree_pred_class_binary <- tree_pred_class == positive_class

sensitivity_tree <- sensitivity(as.factor(tree_pred_class_binary), as.factor(StudentTest_binary), positive = "TRUE")
specificity_tree <- specificity(as.factor(tree_pred_class_binary), as.factor(StudentTest_binary), positive = "TRUE")

sensitivity_tree
specificity_tree
```