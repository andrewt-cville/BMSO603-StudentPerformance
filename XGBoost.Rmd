---
title: "Boosting"
author: "Andrew Thornton"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages

```{r cars}
library(xgboost)
library(e1071)
library(caret)
library(tidyverse)
source('functions.r')
source('data_model.r')
```

## Load and Subset Data

``` {r}
# Load and subset the data
df = get_data()
df$GradeClass = as.numeric(df$GradeClass) - 1
df_sets = subset_data(df)
StudentTrain = data.frame(df_sets[[1]])
StudentTest = data.frame(df_sets[[2]])

train_matrix = sparse.model.matrix(GradeClass ~ ., data=StudentTrain)
train_label = StudentTrain$GradeClass
test_matrix = sparse.model.matrix(GradeClass ~ ., data=StudentTest)
test_label = StudentTest$GradeClass
```

#xgboost

```{r}

params <- list(
  objective = "multi:softprob",
  num_class = 5,
  eta = 0.3,
  max_depth = 6
)

# Train the XGBoost model
xgb_model <- xgboost(
  params = params,
  data = train_matrix,
  label = train_label,
  nrounds = 100
)

xgb.plot.tree(model=xgb_model, trees=0)
pred_probs = predict(xgb_model, test_matrix)
summary(pred_probs)
#putting max class predicted into a matrix to compare to the labels
pred_labels = max.col(matrix(pred_probs, ncol=5, byrow=TRUE)) -1

saveRDS(pred_labels, file="rds/xgb_test.rds")
xgb.plot.multi.trees(xgb_model, trees=0:1)
#Converting accuracy - can uncomment out confusion matrix if you want to see all classes
#confusionMatrix(as.factor(pred_labels), as.factor(test_label))

# Getting Binary classification predictions
pred_labels_binary = factor(ifelse(pred_labels < 2, 1, 0), levels=c(1,0))
test_labels_binary = factor(ifelse(test_label < 2, 1, 0), levels=c(1,0))
confusionMatrix(pred_labels_binary, test_labels_binary)

xgb.plot.importance(xgb.importance(model=xgb_model))
```
